{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ece00c",
   "metadata": {},
   "source": [
    "# Hands-on\n",
    "\n",
    "In this notebook, we provide the necessary steps to partially reproduce the results from our paper \"DeepSolar tracker: towards unsupervised assessment with open-source data of the accuracy of deep learning-based distributed PV mapping\". We run the pipeline over a small area of 600 km² over the Rhône <i> département </i>, covering 42 cities. \n",
    "\n",
    "This notebooks explains setup necessary to run the mapping algorithm. Reproducing the same steps, it is possible to run the algorithm over complete departements in order to completely reproduce our results and even expand them. To do so, we refer the reader to the IGN's [Geoservices portal](https://geoservices.ign.fr/) to download the complete orthoimages and topological data.\n",
    "\n",
    "The data necessary to run this notebook can be downloaded from the [Zenodo repository](https://zenodo.org/record/6862675) associated with the paper. This repository is organized into the following folders:\n",
    "\n",
    "- <b> WEIGHTS </b> : the model weights for the classification and segmentation branch\n",
    "- <b> RNI_2020 </b> : the 2020 edition of the <i> registre national d'installations </i>, which is used to automatically assess the accuracy of the PV mapping. \n",
    "- <b> IGN_TOPO_2021_69 </b> : the topological data for the year 2021 for the Rhône <i> département </i>.\n",
    "- <b> COMMUNES_2021 </b> : the shapefile of the French cities.\n",
    "- <b> IGN_ORTHO_2020_69 </b> : a subset of the orthoimagery for the year 2020 for the Rhône, containing 24 images. These images are provided by the IGN under an open licence. The complete records can be accessed [here](https://geoservices.ign.fr/documentation/donnees/ortho/bdortho). The images are splitted into several folders. Make sure to merge these folders together before further processing.\n",
    "- <b> LOOK_UP_TABLE </b> : The look-up table, used to infer the installations' tilt angle based on their location and surface. We refer the reader to the [paper](https://arxiv.org/abs/2207.07466) for more details on the construction of this table.\n",
    "\n",
    "\n",
    "Please download the data, unzip the folders in a root_folder and specify its path and specify the path to the root folder. In the following, it is assumed that the structure is the following:\n",
    "\n",
    "```python\n",
    "source_dir # Root folder\n",
    "    |\n",
    "    - WEIGHTS # Folder containing the models weights\n",
    "    - RNI_2020 # Folder containing the RNI\n",
    "    - COMMUNES_2021 # Folder containing the shapes of the cities\n",
    "    - IGN_ORTHO_2020_69 # The folder containing the sample of orthoimages\n",
    "    - IGN_TOPO_2021_69 # The folder containing the topological data from 2021 for the Rhône\n",
    "    - LOOK_UP_TABLE # The folder containing the look up table\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20681869",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'path/to/the/data/repository'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c0af5",
   "metadata": {},
   "source": [
    "## 1. Setting up the data and model directories \n",
    "\n",
    "Once the data is downloaded, we need to specify in which directories these files are located. In the cell below, input the local directories. At the end, the `config.yml` file will be automatically edited.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a700d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Source data paths\n",
    "images_directory = os.path.join(root_folder, \"IGN_ORTHO_2020_69\")\n",
    "topological_data_directory =  os.path.join(root_folder, \"IGN_TOPO_2021_69\")\n",
    "model_dir = os.path.join(root_folder, \"WEIGHTS\")\n",
    "cities_directory = os.path.join(root_folder, \"COMMUNES_2021\")\n",
    "look_up_table_dir = os.path.join(root_folder, \"LOOK_UP_TABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e40c8",
   "metadata": {},
   "source": [
    "## 2. Setting up the working directories and the parameters \n",
    "\n",
    "The pipeline is comprised of three parts : classification, segmentation and aggregation. \n",
    "\n",
    "- During classification : tile images are cut into thumbnails and images that contain a PV panel are stored in a dedicated folder\n",
    "- During segmentation : images from the dedicated folder are segmented to delineate the PV panels. The segmentation masks are then converted as polygons and stored in a `geojson` file, located in the `data` folder\n",
    "- During aggregation, PV panels characteristics are extracted. The extraction method is specified by the user.\n",
    "\n",
    "\n",
    "### 2.1. Setting up the working directories\n",
    "\n",
    "These directories are the directories in which the intermediary files and the final outputs will be stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834aeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dir = '../data' # directory that stores the outputs of the model\n",
    "aux_dir = '../aux' # directory that stores the auxiliary outputs used for inference\n",
    "temp_dir = '../temp' # directory in which the temporary outputs are stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acea870",
   "metadata": {},
   "source": [
    "### 2.2. Choosing which parts of the pipeline to execute\n",
    "\n",
    "First of all, we need to choose which parts of the pipeline we want to execute. Since we are lauching the pipeline for the first time, we run all parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classification = True\n",
    "run_segmentation = True\n",
    "run_aggregation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7290964",
   "metadata": {},
   "source": [
    "### 2.3. Setting up the parameters\n",
    "\n",
    "Each part of the pipeline requires some parameters to be executed. \n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "- `tiles_list` : The list of tiles that we want to process\n",
    "\n",
    "By default, this attribute is set to `None`. In this case, the list of tiles to proceed is automatically created in order to map the complete <i> département </i>. In this tutorial, we focus on a subset of 24 tiles, so we input the list of tiles to be proceeded. These tiles are adjacent and cover 42 cities in the west of Lyon.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ba4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_list = [\n",
    "    '69-2020-0815-6525-LA93-0M20-E080', '69-2020-0810-6535-LA93-0M20-E080', '69-2020-0830-6535-LA93-0M20-E080', \n",
    "    '69-2020-0825-6525-LA93-0M20-E080', '69-2020-0820-6535-LA93-0M20-E080', '69-2020-0835-6525-LA93-0M20-E080', \n",
    "    '69-2020-0810-6530-LA93-0M20-E080', '69-2020-0815-6520-LA93-0M20-E080', '69-2020-0820-6530-LA93-0M20-E080', \n",
    "    '69-2020-0835-6520-LA93-0M20-E080', '69-2020-0830-6530-LA93-0M20-E080', '69-2020-0825-6520-LA93-0M20-E080', \n",
    "    '69-2020-0820-6525-LA93-0M20-E080', '69-2020-0835-6535-LA93-0M20-E080', '69-2020-0830-6525-LA93-0M20-E080', \n",
    "    '69-2020-0825-6535-LA93-0M20-E080', '69-2020-0810-6525-LA93-0M20-E080', '69-2020-0815-6535-LA93-0M20-E080', \n",
    "    '69-2020-0830-6520-LA93-0M20-E080', '69-2020-0825-6530-LA93-0M20-E080', '69-2020-0820-6520-LA93-0M20-E080', \n",
    "    '69-2020-0835-6530-LA93-0M20-E080', '69-2020-0815-6530-LA93-0M20-E080', '69-2020-0810-6520-LA93-0M20-E080'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9f399",
   "metadata": {},
   "source": [
    "If you want to run the detection over a complete departement, download a complete archive of a <i> département </i> on the IGN website, specify the path to this archive and set `tiles_list` to `None` in the `config.yml` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e505191",
   "metadata": {},
   "source": [
    "#### Classification and segmentation\n",
    "\n",
    "- `patch_size` : the size of the thumbnail that is passed into the classification and segmentation models\n",
    "- `device` : the device on which inference (classification and segmentation) will be made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3323c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 299 # Assuming one is using the joined pretrained models\n",
    "device = 'cuda' # assuming you have a GPU. Else, replace with 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b476a",
   "metadata": {},
   "source": [
    "#### Classification \n",
    "\n",
    "- `cls_batch_size` : the number of samples to be processed at the same time\n",
    "- `cls_threshold` : the classification threshold (above = PV panel, below = no PV panel)\n",
    "- `cls_model` : the name of the classification model, located in the `models_dir` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_batch_size = 512 # Depends on your available VRAM\n",
    "cls_threshold = 0.4 # assuming you're using the default model\n",
    "cls_model = \"model_bdappv_cls\" # or replace with your own model name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562e87b",
   "metadata": {},
   "source": [
    "#### Segmentation\n",
    "\n",
    "- `seg_threshold` : the segmentation threshold\n",
    "- `num_gpu` : the number of GPUs to be used. Depends on your infrastructure.\n",
    "- `seg_batch_size` : the batch size for segmentation. Depends on your available VRAM\n",
    "- `seg_model` : the name of the segmentation model in the `models_dir` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fe06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_threshold = 0.46\n",
    "num_gpu = 1\n",
    "seg_batch_size = 128\n",
    "seg_model = 'model_bdappv_seg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c423025",
   "metadata": {},
   "source": [
    "#### Aggregation\n",
    "\n",
    "- `filter_building` : whether the polygons should be matched with a building \n",
    "- `filter_LUT` : True : whether the tilt is inputed using the look up table\n",
    "- `constant_kWp` : False : whether the installed capacity is estimated from the surface area using a linear regression model or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d005113",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_building = True \n",
    "filter_LUT = True\n",
    "constant_kWp = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648fef03",
   "metadata": {},
   "source": [
    "Finally, we edit the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d4175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Edit the config file\n",
    "\n",
    "with open(\"../config.yml\") as f:\n",
    "     config = yaml.safe_load(f)\n",
    "        \n",
    "        \n",
    "# edit the values\n",
    "\n",
    "config['source_images_dir'] = images_directory\n",
    "config['model_dir'] = model_dir\n",
    "config['source_commune_dir'] = cities_directory\n",
    "config['source_topo_dir'] = topological_data_directory\n",
    "config['look_up_table_dir'] = look_up_table_dir\n",
    "\n",
    "config['temp_dir'] = temp_dir\n",
    "config['aux_dir'] = aux_dir\n",
    "config['outputs_dir'] = outputs_dir\n",
    "\n",
    "config['run_classification'] = run_classification\n",
    "config['run_segmentation'] = run_segmentation\n",
    "config['run_aggregation'] = run_aggregation\n",
    "\n",
    "config['tiles_list'] = tiles_list\n",
    "\n",
    "config['patch_size'] = patch_size\n",
    "config['device'] = device\n",
    "\n",
    "config['cls_threshold'] = cls_threshold\n",
    "config['cls_model'] = cls_model\n",
    "config['cls_batch_size'] = cls_batch_size\n",
    "\n",
    "config['seg_threshold'] = seg_threshold \n",
    "config['seg_batch_size'] = seg_batch_size\n",
    "config['seg_model'] = seg_model\n",
    "config['num_gpu'] = num_gpu\n",
    "\n",
    "config['filter_building'] = filter_building\n",
    "config['filter_LUT'] =  filter_LUT\n",
    "config['constant_kWp'] = constant_kWp\n",
    "\n",
    "# save the config file\n",
    "# the configuration file is saved in the notebook folder. The original config file, which\n",
    "# is used if the script is run from the command line, remains unedited.\n",
    "with open(\"config.yml\", \"w\") as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664fc307",
   "metadata": {},
   "source": [
    "## 3. A first run\n",
    "\n",
    "If you are doing inference on a <i> département </i> for the first time, you <b> first need to run the `auxiliary.py` script </b>. This script generate the auxiliary data that is then used throughout the main pipeline. To run this script, enter the <i> département </i> number and execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../scripts/pipeline_components/')\n",
    "sys.path.append('../scripts/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd345bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run ../auxiliary.py --dpt=69"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6241ef",
   "metadata": {},
   "source": [
    "Once the auxiliary files have been generated, the main pipeline can be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da73478",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run ../main.py --dpt=69"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63df8707",
   "metadata": {},
   "source": [
    "This is it ! We mapped all installations on our target area. The files generated are the following : \n",
    "- `arrays_{dpt}.geojson` : the file with all segmentation polygons obtained at the end of the segmentation stage.\n",
    "- `arrays_characteristics_{dpt}.geojson` : a file with the polygons of all installations after filtering. The characteristics of the polygons are also reported.\n",
    "- `characteristics_{dpt}.csv` : a file where each row is an installation. Contains the characteristics and the localization of the installation.\n",
    "- `aggregated_characterisitcs_{dpt}.csv` : aggregates the installed capacity and number of installations per city.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36202a06",
   "metadata": {},
   "source": [
    "## 4. Assessing the accuracy of the detections\n",
    "\n",
    "Now that we've detected our installations, we want to measure the accuracy of the estimates. To do so, we leverage the <i> registre national d'installations </i> (RNI). The RNI aggregates the installed capacity of installations below 36 kWc by city. When evaluating our outputs, we compare our estimates with this reference. \n",
    "\n",
    "#### Setting up the directory and running the evaluation script\n",
    "\n",
    "The RNI is located in the directory `rni_dir`. We specify the complete path to the RNI and the name of the file, and run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200136b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rni_path = os.path.join(root_folder, \"RNI_2020\")\n",
    "filename = 'RNI_2020.json'\n",
    "rni_path # Display the source dir and copy/paste it as the argument `--source_dir` in the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29212dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the evaluation\n",
    "# we also manually input the `evaluatoin dir` where the results of the evaluation will be stored.\n",
    "%run ../evaluate.py --dpt=69 --filename='RNI_2020.json' --source_dir='/paste/the/directory/here' --evaluation_dir='../evaluation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f529a0",
   "metadata": {},
   "source": [
    "The outputs are located in the newly created `evaluation_dir` directory. If you want to visualize your outputs, go to the `visualization.ipynb` notebook !\n",
    "\n",
    "Additionally, you can remove the `config.yml` file which has been used for this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464541db",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53811350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsfrance",
   "language": "python",
   "name": "dsfrance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
